{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithya03/Seawise-giant/blob/main/Seawise_Giant_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAIsd4GWYenr"
      },
      "outputs": [],
      "source": [
        "# linear algebra\n",
        "import numpy as np\n",
        "\n",
        "# data processing\n",
        "import pandas as pd #data analysis and manipulation\n",
        "\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "%matplotlib inline  # tells the IPython environment to draw the plots immediately after the current cell.\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "# Algorithms\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GLxEsU8Yr7x"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"/content/sample_data/test.csv\")\n",
        "train_df = pd.read_csv(\"/content/sample_data/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laqv2szhkC-n"
      },
      "outputs": [],
      "source": [
        " train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7G3wVN7ZjKA",
        "outputId": "fb00fc6f-7f0f-4c75-9bda-723ccd92e479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 12 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   Survived         100000 non-null  int64  \n",
            " 1   Pclass           100000 non-null  int64  \n",
            " 2   Sex              100000 non-null  int64  \n",
            " 3   Age              100000 non-null  int64  \n",
            " 4   SibSp            100000 non-null  int64  \n",
            " 5   Fare             100000 non-null  int64  \n",
            " 6   Embarked         100000 non-null  int64  \n",
            " 7   relatives        100000 non-null  int64  \n",
            " 8   Deck             100000 non-null  int64  \n",
            " 9   Title            100000 non-null  float64\n",
            " 10  Age_Class        100000 non-null  int64  \n",
            " 11  Fare_Per_Person  100000 non-null  int64  \n",
            "dtypes: float64(1), int64(11)\n",
            "memory usage: 9.2 MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io5-5umhZrxH"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N61r0z2WZyLv"
      },
      "outputs": [],
      "source": [
        "#used to identify mull or missing values\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)#decending order\n",
        "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
        "missing_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGaqx2_gkKdy"
      },
      "outputs": [],
      "source": [
        " train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH-0a2BNalB6"
      },
      "outputs": [],
      "source": [
        "survived = 'survived'\n",
        "not_survived = 'not survived'\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
        "women = train_df[train_df['Sex']=='female']\n",
        "men = train_df[train_df['Sex']=='male']\n",
        "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n",
        "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n",
        "ax.legend()\n",
        "ax.set_title('Female')\n",
        "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n",
        "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n",
        "ax.legend()\n",
        "_ = ax.set_title('Male')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgEdQojBasNM"
      },
      "outputs": [],
      "source": [
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked', aspect=1.6)\n",
        "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None ) #pointplot , x-axis, y-axis , grouping varable\n",
        "FacetGrid.add_legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq8x2xI2a_29"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x='Pclass', y='Survived', data=train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OVM8KcnbEm_"
      },
      "outputs": [],
      "source": [
        "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', aspect=1.6)\n",
        "grid.map(plt.hist, 'Age', alpha=.5, bins=20) #learning rate\n",
        "grid.add_legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJWNYURQbLrZ"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
        "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
        "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
        "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
        "train_df['not_alone'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVmAIy3gbWdS"
      },
      "outputs": [],
      "source": [
        "#data preprocessing\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mine\n"
      ],
      "metadata": {
        "id": "7WxGYeCy3C_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiGc658Fb7YS"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop(['PassengerId'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMygxv9jcNoD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}# deck dictionary\n",
        "data = [train_df, test_df]#for both test and train files\n",
        "\n",
        "for dataset in data:#creates a new feature based on deck and cabin\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")#fill null values with u0\n",
        "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())#take the first letter of cabin and map it to deckk dictionary\n",
        "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
        "    dataset['Deck'] = dataset['Deck'].fillna(0)#fill other values with 0\n",
        "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
        "# we can now drop the cabin feature\n",
        "train_df = train_df.drop(['Cabin'], axis=1)#drop cabin from both files (coloumns)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA_CDAC5cPhq"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]#imputing missing values in age coloumn\n",
        "\n",
        "for dataset in data:\n",
        "    mean = train_df[\"Age\"].mean()\n",
        "    std = test_df[\"Age\"].std()\n",
        "    is_null = dataset[\"Age\"].isnull().sum()\n",
        "    # compute random numbers between the mean, std and is_null\n",
        "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)#radint fill them\n",
        "    # fill NaN values in Age column with random values generated\n",
        "    age_slice = dataset[\"Age\"].copy()\n",
        "    age_slice[np.isnan(age_slice)] = rand_age\n",
        "    dataset[\"Age\"] = age_slice\n",
        "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
        "train_df[\"Age\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MkgJs-zk9Np"
      },
      "outputs": [],
      "source": [
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw0mjxQQcjII",
        "outputId": "3f5b969d-b656-4992-8a6b-af6561ce48f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    100000.000000\n",
              "mean          0.330350\n",
              "std           0.574197\n",
              "min           0.000000\n",
              "25%           0.000000\n",
              "50%           0.000000\n",
              "75%           1.000000\n",
              "max           2.000000\n",
              "Name: Embarked, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "train_df['Embarked'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQxfTw2tcqDe"
      },
      "outputs": [],
      "source": [
        "common_value = 'S'\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81SsWxRicwzV"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPk4ADr4jg35"
      },
      "outputs": [],
      "source": [
        " train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw1Et5lzc_70"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drkdt9hIdCGy"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "\n",
        "for dataset in data:\n",
        "    # extract titles\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # replace titles with a more common title or as Rare\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
        "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    # convert titles into numbers\n",
        "    dataset['Title'] = dataset['Title'].map(titles)\n",
        "    # filling NaN with 0, to get safe data\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "train_df = train_df.drop(['Name'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShEpjWvUF-ta"
      },
      "outputs": [],
      "source": [
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3jkwXb3dN3a"
      },
      "outputs": [],
      "source": [
        "genders = {\"male\": 0, \"female\": 1}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Sex'] = dataset['Sex'].map(genders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsCGsma6dhcF"
      },
      "outputs": [],
      "source": [
        "train_df['Ticket'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HclYFkmdkmQ"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOTK2pEvd1zU"
      },
      "outputs": [],
      "source": [
        "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map(ports)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPY7vovOeDFH"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    #dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7CqrvmJlLQD"
      },
      "outputs": [],
      "source": [
        "train_df['Age'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBdJsKOxjIeY"
      },
      "outputs": [],
      "source": [
        " train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2vPJg-Ri-5Z"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
        "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
        "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO3jkO4zebJQ"
      },
      "outputs": [],
      "source": [
        " train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aisHreb2lbF0"
      },
      "outputs": [],
      "source": [
        "#new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtlQSnUClpNt"
      },
      "outputs": [],
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age_Class']= dataset['Age']* dataset['Pclass'] #why"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcPPtUMDly11"
      },
      "outputs": [],
      "source": [
        "for dataset in data:\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
        "# Let's take a last look at the training set, before we start training the models.\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "till here"
      ],
      "metadata": {
        "id": "dXwQv9th3Qv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv1QQ9XYnfd_"
      },
      "outputs": [],
      "source": [
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltVCpSInnl34"
      },
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=200)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJTC6pBLn2Vf"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "\n",
        "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxCXsTDOoBXc"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(X_train, Y_train)\n",
        "Y_pred = knn.predict(X_test)\n",
        "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqGTR4PwoOr0"
      },
      "outputs": [],
      "source": [
        "gaussian = GaussianNB()\n",
        "gaussian.fit(X_train, Y_train)\n",
        "Y_pred = gaussian.predict(X_test)\n",
        "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CKHB04MoW2K"
      },
      "outputs": [],
      "source": [
        "perceptron = Perceptron(max_iter=10)\n",
        "perceptron.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = perceptron.predict(X_test)\n",
        "\n",
        "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK1MjKcOoep2"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywjKan7Boxx1"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'Model': [ 'KNN', 'Logistic Regression',\n",
        "              'Random Forest', 'Naive Bayes', 'Perceptron',\n",
        "               'Decision Tree'],\n",
        "    'Score': [ acc_knn, acc_log,\n",
        "              acc_random_forest, acc_gaussian, acc_perceptron,\n",
        "               acc_decision_tree]})\n",
        "result_df = results.sort_values(by='Score', ascending=False)\n",
        "result_df = result_df.set_index('Score')\n",
        "result_df.head(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0V-b4zzpb17"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "scores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\n",
        "print(\"Scores:\", scores)\n",
        "print(\"Mean:\", scores.mean())\n",
        "print(\"Standard Deviation:\", scores.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ih8lqb8p1Bl"
      },
      "outputs": [],
      "source": [
        "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
        "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
        "importances.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0tGruaIp4ld"
      },
      "outputs": [],
      "source": [
        "importances.plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txsDkRVcp899"
      },
      "outputs": [],
      "source": [
        "train_df  = train_df.drop(\"not_alone\", axis=1)\n",
        "test_df  = test_df.drop(\"not_alone\", axis=1)\n",
        "\n",
        "train_df  = train_df.drop(\"Parch\", axis=1)\n",
        "test_df  = test_df.drop(\"Parch\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wBYrwrIDqADE"
      },
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)\n",
        "\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "print(round(acc_random_forest,2,), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fliCvI2eqO-w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = cross_val_predict(random_forest, X_train, Y_train, cv=3)\n",
        "confusion_matrix(Y_train, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2IGEEZgqpH5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision:\", precision_score(Y_train, predictions))\n",
        "print(\"Recall:\",recall_score(Y_train, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-JF0miPuqzM8"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JNBaxRbctaUD"
      },
      "outputs": [],
      "source": [
        "# Create a submission file with the predicted survival outcomes for each passenger in the test set\n",
        "#ON TRAIN DATA\n",
        "submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': Y_train})\n",
        "submission_df.to_csv('submission.csv',index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c0kLz5ag0tzR"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': Y_prediction})\n",
        "submission_df.to_csv('submission.csv',index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}